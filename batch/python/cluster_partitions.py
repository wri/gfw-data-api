#!/usr/bin/env python

import json
import os

import click
import psycopg2


@click.command()
@click.option("-d", "--dataset", type=str, help="Dataset name")
@click.option("-v", "--version", type=str, help="Version name")
@click.option("-p", "--partition_type", type=str, help="Partition type")
@click.option("-P", "--partition_schema", type=str, help="Partition schema")
@click.option("-x", "--index_type", type=str, help="Index type used for clustering")
@click.option("-C", "--column_names", type=str, help="Column used for clustering")
def cli(
    dataset: str,
    version: str,
    partition_type: str,
    partition_schema: str,
    index_type: str,
    column_names: str,
) -> None:

    click.echo(
        f"python cluster_partitions.py -d {dataset} -v {version} -p {partition_type} -P {partition_schema} -x {index_type} -c {column_names}"
    )

    connection = psycopg2.connect(
        database=os.environ["PGDATABASE"],
        user=os.environ["PGUSER"],
        password=os.environ["PGPASSWORD"],
        port=os.environ["PGPORT"],
        host=os.environ["PGHOST"],
    )
    cursor = connection.cursor()

    column_names_underscored = "_".join(column_names.split(","))

    # NOTE: Index names for partition tables are auto generated by PostgreSQL
    # and slightly vary from the naming convention we use when creating the main index.
    # As far as I can tell, it `tablename_columnname_idx`. It does not include the index type.

    # HashSchema = int
    if partition_type == "hash":
        partition_count: int = json.loads(partition_schema)["partition_count"]
        for i in range(partition_count):
            sql = f"""CLUSTER "{dataset}"."{version}_{i}" USING "{version}_{i}_{column_names_underscored}_idx\";"""
            click.echo(sql)
            cursor.execute(sql)

    # ListSchema = Dict[str, List[str]]
    elif partition_type == "list":
        partition_list: list = json.loads(partition_schema)
        for partition in partition_list:
            sql = f"""CLUSTER "{dataset}"."{version}_{partition["partition_suffix"]}" USING "{version}_{partition["partition_suffix"]}_{column_names_underscored}_idx\";"""
            click.echo(sql)
            cursor.execute(sql)

    # RangeSchema = Dict[str, Tuple[Any, Any]]
    elif partition_type == "range":
        partition_list = json.loads(partition_schema)
        for partition in partition_list:
            sql = f"""CLUSTER "{dataset}"."{version}_{partition["partition_suffix"]}" USING "{version}_{partition["partition_suffix"]}_{column_names_underscored}_idx\";"""
            click.echo(sql)
            cursor.execute(sql)

    else:
        NotImplementedError(
            "The Partition type and schema combination is not supported"
        )

    connection.commit()
    cursor.close()
    connection.close()


if __name__ == "__main__":
    cli()
